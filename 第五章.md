第五章、优化程序性能
=========
#### 写在前面
写程序最主要的目标就是使它在所有可能的情况下都正确工作。一个运行得很快但是
给出错误结果的程序没有任何用处。程序员必须写出清晰简洁的代码，这样做不仅是为了
自己能够看懂代码，也是为了在检查代码和今后需要修改代码时，其他人能够读懂和理解
代码。
另一方面，在很多情况下，让程序运行得快也是一个重要的考虑因素。如果一个程序
要实时地处理视频帧或者网络包，一个运行得很慢的程序就不能提供所需的功能。当一个
计算任务的计算量非常大，需要执行数日或者数周，那么哪怕只是让它运行得快 20%也会
产生重大的影响。本章会探讨如何使用几种不同类型的程序优化技术，使程序运行得
更快。点：第一，我们必须选择一组适当的算法和数据结构。第二，我们必须编写出编译器能够有效优化以转换成高效可执行代码的源代码。
第三项技术针对处理运算量特别大的计算，将一个任务分成多个部分，这些部分可以在多核和
多处理器的某种组合上并行地计算。

#### 5.1 优化编译器的能力和局限性
编译器必须很小心地对程序只使用安全的优化，也就是说对于程序可能遇到的所有可
能的情况，在 C 语言标准提供的保证之下，优化后得到的程序和未优化的版本有一样的行
为。限制编译器只进行安全的优化，消除了造成不希望的运行时行为的一些可能的原因，
但是这也意味着程序员必须花费更大的力气写出编译器能够将之转换成有效机器代码的程
序。
在各种编译器中，就优化能力来说，GCC 被认为是胜任的，但是并不是特别突出。
它完成基本的优化，但是它不会对程序进行更加“有进取心的”编译器所做的那种激进变
换。因此，使用 GCC的程序员必须花费更多的精力，以一种简化编译器生成高效代码的
任务&方式来编写程序。
#### 5.2 表示程序性能
引人度量标准每元素的周期数（Cycles Per Element, CPE), 作为一种表示程序性
能并指导我们改进代码的方法。CPE 这种度量标准帮助我们在更细节的级别上理解迭代程
序的循环性能。这样的度量标准对执行重复计算的程序来说是很适当的，例如处理图像中
的像素，或是计算矩阵乘积中的元素。
处理器活动的顺序是由时钟控制的，时钟提供了某个频率的规律信号，通常用千兆赫兹(GHz), 即十亿周期每秒来表示。
对于较大的
n 的值（比如说大于 200)，运行时间就会主要由线性因子来决定。这些项中的系数称为每
元素的周期数(简称 CPE)的有效值。注意，我们更愿意用每个元素的周期数而不是每次循环
的周期数来度量，这是因为像循环展开这样的技术使得我们能够用较少的循环完成计算，而
我们最终关心的是，对于给定的向量长度，程序运行的速度如何。
#### 5.3 程序示例
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20203326.png)  
```C
typedef struct {
long len;
data_t *data;
}vec_rec,*vec_ptr;
```
这个声明用 data_t 来表示基本元素的数据类型。在测试中，我们度量代码对于整数（C 语
言的 int 和 long)和浮点数（C 语言的 float 和 double)数据的性能。为此，我们会分别
为不同的类型声明编译和运行程序，就像下面这个例子对数据类型 long —样：  
typedef long data_t;  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20204023.png)  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20204035.png)  
#### 5.4 消除循环的低效率
过程 combinel 调用函数 vec_length 作为 for 循环的测试条件,每
次循环迭代时都必须对测试条件求值。另一方面，向量的长度并不会随着循环的进行而改变。因此，只需计算一次向量的长度，然后在我们的测试条件中都使用这个值。  
combine2 它在开始时调用 vec_length 并将结
果赋值给局部变量 length。  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20204253.png)  
#### 5.5 减少过程调用
过程调用会带来开销，而且妨碍大多数形式的程序优化。  
作为替代，假设为我们的抽象数据类型增加一个函数 get_Vec_start这个函数返回
数组的起始地址。它没有用函数调用来获取每个向量元素，而是直接访问数组。  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20204715.png)  
#### 5.6 消除不必要的内存引用
combine 的代码将合并运算计算的值累积在指针 dest 指定的位置。通过检查编译
出来的为内循环产生的汇编代码，可以看出这个属性。在此我们给出数据类型为 double,
合并运算为乘法的 x86-64 代码：
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20204823.png)  
在这段循环代码中，我们看到，指针 dest 的地址存放在寄存器 * rbx 中，它还改变了
代码，将第 i 个数据元素的指针保存在寄存器%rdx中，注释中显示为 data+i 每次迭
代，这个指针都加 8。循环终止操作通过比较这个指针与保存在寄存器％rax 中的数值来判
断。我们可以看到每次迭代时，累积变量的数值都要从内存读出再写人到内存。这样的读
写很浪费，因为每次迭代开始时从 dest 读出的值就是上次迭代最后写人的值。  
我们能够消除这种不必要的内存读写,引人一个临时变量 acc 它在循环中用来累积计算出来的值。只有在循环完成之后结
果才存放在 dest 中。  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20205009.png)  
#### 5.7 理解现代处理器
随着试图进一步提高性能，必须考虑利用处理器微体系结构的优
化，也就是处理器用来执行指令的底层系统设计。要想充分提髙性能，需要仔细分析程
序，同时代码的生成也要针对目标处理器进行调整。详细性能结
果，对其他机器不一定有同样的效果，但是操作和优化的通用原则对各种各样的机器都
适用。  
在代码级上，看上去似乎是一次执行一条指令，每条指令都包括从寄存器或内存取
值，执行一个操作，并把结果存回到一个寄存器或内存位置。在实际的处理器中，是同时
对多条指令求值的，这个现象称为指令级并行。现代微处理器取得的了不起的功绩之一是：它们采用复杂而奇异
的微处理器结构，其中，多条指令可以并行地执行，同时又呈现出一种简单的顺序执行指
令的表象。   
当一系列操作必须按照严格顺序执行时，就会遇到延迟界限（latency
bound) 因为在下一条指令开始之前，这条指令必须结束。当代码中的数据相关限制了处
理器利用指令级并行的能力时，延迟界限能够限制程序性能。吞吐量界限（throughput
tcnmd)刻画了处理器功能单元的原始计算能力。这个界限是程序性能的终极限制。
#### 5.7.1 整体操作
现代微处理器的一个非常简单化的示意图。我们假想的处理器设计是不太
严格地基于近期的 Intel 处理器的结构。这些处理器在工业界称为超标量（superscalar)，
意思是它可以在每个时钟周期执行多个操作，而且是乱序的（out-of-order)，意思就是指令
执行的顺序不一定要与它们在机器级程序中的顺序一致。整个设计有两个主要部分：指令
控制单元（Instruction Control Unit, ICU) 和执行单元（Execution Unit, EU)前者负责
从内存中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作；而后者
执行这些操作。  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20205537.png)  
ICU 从指令高速缓存（instruction cache)中读取指令，指令高速缓存是一个特殊的高
速存储器，它包含最近访问的指令。通常，ICU 会在当前正在执行的指令很早之前取指,
这样它才有足够的时间对指令译码，并把操作发送到 EU。  
一个问题是当程序遇到分支时，程序有两个可能的前进方向。一种可能会选择分支，控制被传递到分支目标。
另一种可能是，不选择分支，控制被传递到指令序列的下一条指令。现代处理器采用了一
种称为分支预测（branch prediction)的技术，处理器会猜测是否会选择分支，同时还预测
分支的目标地址。使用投机执行（speculative execution)的技术，处理器会开始取出位于它
预测的分支会跳到的地方的指令，并对指令译码，甚至在它确定分支预测是否正确之前就
开始执行这些操作。如果过后确定分支预测错误，会将状态重新设置到分支点的状态，并
开始取出和执行另一个方向上的指令。标记为取指控制的块包括分支预测，以完成确定取
哪些指令的任务。  
指令译码逻辑接收实际的程序指令，并将它们转换成一组基本操作(有时称为微操作)。
每个这样的操作都完成某个简单的计算任务，例如两个数相加，从内存中读数据，或是向内
存写数据。对于具有复杂指令的机器，比如 x86 处理器，一条指令可以被译码成多个操作。
关于指令如何被译码成操作序列的细节，不同的机器都会不同，这个信息可谓是高度机密。
幸运的是，不需要知道某台机器实现的底层细节，我们也能优化自己的程序。  
EU 接收来自取指单元的操作。通常，每个时钟周期会接收多个操作。这些操作会被
分派到一组功能单元中，它们会执行实际的操作。这些功能单元专门用来处理不同类型的
操作。  
读写内存是由加载和存储单元实现的。加载单元处理从内存读数据到处理器的操作。
这个单元有一个加法器来完成地址计算。类似，存储单元处理从处理器写数据到内存的操
作。  
使用投机执行技术对操作求值，但是最终结果不会存放在程序寄存器或数据内存中，
直到处理器能确定应该实际执行这些指令。分支操作被送到 EU, 不是确定分支该往哪里
去，而是确定分支预测是否正确。如果预测错误，EU 会丢弃分支点之后计算出来的结果。
它还会发信号给分支单元，说预测是错误的，并指出正确的分支目的。在这种情况中，分
支单元开始在新的位置取指。  
在 ICU 中，退役单元（retirement unit)记录正在进行的处理，并确保它遵守机器级程
序的顺序语义。  
指令译码时,关于指令的信息被放置在一个先进先出的队列中。这个信息会一直保持在队列中，直到发
生以下两个结果中的一个。首先，一旦一条指令的操作完成了，而且所有引起这条指令的
分支点也都被确认为预测正确，那么这条指令就可以退役（retired)了，所有对程序寄存器
的更新都可以被实际执行了。另一方面，如果引起该指令的某个分支点预测错误，这条指
令会被清空（flushed)，丢弃所有计算出来的结果。通过这种方法，预测错误就不会改变程
序的状态了。  
控制操作数在执行单元间传送的最常见的机制称为寄存器重命名。
#### 5.7.2 功能单元的性能
从整数运算到浮点运算，延迟是增加的。还可以看到加法和乘法运算的发
射时间都为 1，意思是说在每个时钟周期，处理器都可以开始一条新的这样的运算。这种
很短的发射时间是通 过使用流水线实现的。流水线化的功能单元实现为一系列的阶段
(Stage)。 每个阶段完成一部分的运算。例如，一个典型的浮点加法器包含三个阶段（所以
有三个周期的延返)i 一个阶段处理指数值，一个阶段将小数相加，，祖努一个阶段对结果
进行舍人。算术运算可以连续地通过各个阶段，而不用等待一个操作完成后再开始下一
个。只有当要执行的运算是连续的、逻辑上独立的时候，才能利用这种功能。发射时间为
1 的功能单元被称为完全流水线化的（fully pipelined): 每个时钟周期可以开始一个新的运
算。  
我们还看到，除法器(用于整数和浮点除法，还用来计算浮点平方根）不是完全流水线
化的——它的发射时间等于它的延迟。这就意味着在开始一条新运算之前，除法器必须完
成整个除法。  
表达发射时间的一种更常见的方法是指明这个功能单元的最大呑吐量，定义为发射时
间的倒数。一个完全流水线化的功能单元有最大的吞吐量，每个时钟周期一个运算，而发
射时间较大的功能单元的最大吞吐量比较小。具有多个功能单元可以进一步提髙吞吐量。  
延迟界限给出了任何必须按照严格顺序完成合并运算的函数所需要的最小 CPE 值。根据
功能单元产生结果的最大速率，呑吐量界限给出了 CPE 的最小界限。例如，因为只有一
个整数乘法器，它的发射时间为 1 个时钟周期，处理器不可能支持每个时钟周期大于 1 条
乘法的速度。  
#### 5.7.3 处理器操作的抽象模型
作为分析在现代处理器上执行的机器级程序性能的一个工具，我们会使用程序的数据
流（data-flow)表示，这鳥一种图形化的表示方法，展现了不同操作之间的数据相关是如何
限制它们的执行顺序的。这些限制形成了图中的关键路径（critical path>, 这是执行一组机
器指令所需时钟周期数的一个下界。  
1. 从机器级代码到数据流图   
这个循环编译出的代码由 4 条指令组成，寄存器 %rdx 存放指向数组 data
中第 i 个元素的指针，%rax 存放指向数组末尾的指针，而％xmm0 存放累积值 acc。  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20210819.png)  
寄存器 %rax 只被 cmp 操作作为源值，因此这个寄存器在循环结束时
有着同循环开始时一样的值。另一方面，在循环中，寄存器 %rdx 既被使用也被修改。它
的初始值被 load 和 add 操作使用；它的新值由 add 操作产生，然后被 cmp 操作使用。在
循环中，mul 操作首先使用寄存器 %xmm0 的初始值作为源值，然后会修改它的值。  
对于形成循环的代码片段，我们可以将访问到的寄存器分为四类：  
只读：这些寄存器只用作源值，可以作为数据，也可以用来计算内存地址，但是在循
环中它们是不会被修改的。循环 combine 的只读寄存器是%rax。  
只写：这些寄存器作为数据传送操作的目的。在本循环中没有这样的寄存器。  
局部：这些寄存器在循环内部被修改和使用，迭代与迭代之间不相关。在这个循环
中，条件码寄存器就是例子：cmp 操作会修改它们，然后 jne 操作会使用它们，不过这种
相关是在单次迭代之内的。  
循环：对于循环来说，这些寄存器既作为源值，又作为目的，一次迭代中产生的值会
在另一次迭代中用到。可以看到，%rdx 和%xmm0 是 combine4 的循环寄存器，对应于程序值 data+i 和 acc。  
2. 其他性能因素  
数据流表示中的关键路径提供的只是程序需要周期数的下界。还
有其他一些因素会限制性能，包括可用的功能单元的数量和任何一步中功能单元之间能够
传递数据值的数量。对于合并运算为整数加法的情况，数据操作足够快，使得其他操作供
应数据的速度不够快。  
我们对程序操作的抽象数据流表示说明，combine4的关键路径长 L • n 是由对程序值acc 的连续更新造成的，这条路径将 CPE 限制为最多L。
看上去，延迟界限是基本的限制，决定了我们的合并运算能执行多快。接下来的任务
是重新调整操作的结构，增强指令级并行性。  
#### 5.8 循环展开
循环展开是一种程序变换，通过增加每次迭代计算的元素的数量，减少循环的迭代次数。  
循环展开能够从两个方面改进程序的性能。首先，它减少了不直接
有助于程序结果的操作的数量，例如循环索引计算和条件分支。第二，它提供了一些方
法，可以进一步变化代码，减少整个计算中关键路径上的操作数量。  
#### 5.9 提局并行性
程序的性能是受运算单元的延迟限制的。不过，正如我们表明的，执行加法和乘
法的功能单元是完全流水线化的，这意味着它们可以每个时钟周期开始一个新操作，并且有
些操作可以被多个功能单元执行。硬件具有以更高速率执行乘法和加法的潜力，但是代码不
能利用这种能力，即使是使用循环展开也不能，这是因为我们将累积值放在一个单独的变量
acc 中。在前面的计算完成之前，都不能计算 acc 的新值。虽然计算 acc 新值的功能单元能
够每个时钟周期开始一个新的操作，但是它只会每 L 个周期开始一条新操作，这里 L 是合并
操作的延迟。现在我们要考察打破这种顺序相关，得到比延迟界限更好性能的方法。  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20211705.png)  
#### 5.9.1 多个累积变量
对于一个可结合和可交换的合并运算来说，比如说整数加法或乘法，我们可以通过将
一组合并运算分割成两个或更多的部分，并在最后合并结果来提高性能。  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20211812.png)  
#### 5.9.2 重新结合变换
内循环中元素合并的方式。  
差别仅在于两个括号是如何放置的。我们称之为 重新结合变换， 因为括号改变了向量元素与累积值acc的合并顺序。  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20212130.png)  
#### 5.10 优化合并代码的结果小结
使用多项优化技术，我们获得的 CPE 已经接近于 0.50 和 1.00 的吞吐量界限，只受
限于功能单元的容量。与原始代码相比提升了 10 20 倍，且使用普通的 C 代码和标准编
译器就获得了所有这些改进。重写代码利用较新的 SIMD 指令得到了将近 4 倍或 8 倍的性
能提升。比如单精度乘法，CPE 从初值 11.14 降到了 0.06, 整体性能提升超过 180 倍。  
#### 5.11 —些限制因素 
我们已经看到在一个程序的数据流图表示中，关键路径指明了执行该程序所需时间的
一个基本的下界。也就是说，如果程序中有某条数据相关链，这条链上的所有延迟之和等
于T, 那么这个程序至少需要 T 个周期才能执行完。  
我们还看到功能单元的吞吐量界限也是程序执行时间的一个下界。也就是说，假设一
个程序一共需要 N 个某种运算的计算，而微处理器只有 C 个能执行这个操作的功能单元,
并且这些单元的发射时间为 I。那么，这个程序的执行至少需要 N•I/C 个周期。
#### 5.11.1 寄存器溢出
循环并行性的好处受汇编代码描述计算的能力限制。如果我们的并行度 p 超过了可用
的寄存器数量，那么编译器会诉诸溢出（spilling)，将某些临时值存放到内存中，通常是在
运行时堆栈上分配空间。我们可以看到对这种循环展开程度的增加没有改善 CPE, 有些甚至还变差了。一旦编译器必须要诉诸寄存器溢出，那么维护多个累积变量的优势就很可能消失。幸
运的是，X86-64 有足够多的寄存器，大多数循环在出现寄存器溢出之前就将达到吞吐量
限制。
#### 5.11.2 分支预测和预测错误处罚
当分支预测逻辑不能正确预测一个分支是否要跳转的时
候，条件分支可能会招致很大的预测错误处罚。现代处理器的工作远超前于当前正在执行的指令，从内存读新指令，译码指令，以确
定在什么操作数上执行什么操作。只要指令遵循的是一种简单的顺序，那么这种指令流水
线化(instruction pipelining)就能很好地工作。当遇到分支的时候，处理器必须猜测分支该
往哪个方向走。对于条件转移的情况，这意味着要预测是否会选择分支。对于像间接跳转
(跳转到由一个跳转表条目指定的地址）或过程返回这样的指令，这意味着要预测目标地
址。在这里，我们主要讨论条件分支。  
在一个使用投机执行（speculative execution)的处理器中，处理器会开始执行预测的分
支目标处的指令。它会避免修改任何实际的寄存器或内存位置，直到确定了实际的结果。
如果预测正确，那么处理器就会“提交”投机执行的指令的结果，把它们存储到寄存器或
内存。如果预测错误，处理器必须丢弃掉所有投机执行的结果，在正确的位置，重新开始
取指令的过程。这样做会引起预测错误处罚，因为在产生有用的结果之前，必须重新填充
指令流水线。  
在编译条件语句和表达式的时候，GCC 能产生使用这些指令的代
码，而不是更传统的基于控制的条件转移的实现。翻译成条件传送的基本思想是计算出一
个条件表达式或语句两个方向上的值，然后用条件传送选择期望的值。  
1.不要过分关心可预测的分支  
我们已经看到错误的分支预测的影响可能非常大，但是这并不意味着所有的程序分支
都会减缓程序的执行。实际上，现代处理器中的分支预测逻辑非常善于辨别不同的分支指
令的有规律的模式和长期的趋势。。例如，在合并函数中结束循环的分支通常会被预测为选
择分支，因此只在最后一次会导致预测错误处罚。  
2. 书写适合用条件传送实现的代码  
分支预测只对有规律的模式可行。程序中的许多测试是完全不可预测的，依赖于数据
的任意特性，例如一个数是负数还是正数。对于这些测试，分支预测逻辑会处理得很糟
糕。对于本质上无法预测的情况，如果编译器能够产生使用条件数据传送而不是使用条件
控制转移的代码，可以极大地提高程序的性能。这不是 C 语言程序员可以直接控制的，但
是有些表达条件行为的方法能够更直接地被翻译成条件传送，而不是其他操作。  
我们发现 GCC 能够为以一种更“功能性的”风格书写的代码产生条件传送，在这种
风格的代码中，我们用条件操作来计算值，然后用这些值来更新程序状态，这种风格对立
与一种更“命令式的”风格，这种风格中，我们用条件语句来有选择地更新程序状态。
#### 5.12 理解内存性能
所有的现代处理器都包含一个或多个高 速缓存（cache)存储器，以对这样少
量的存储器提供快速的访问。本节会进一步研究涉及加载（从内存读到寄存器）和存储(从
寄存器写到内存)操作的程序的性能，只考虑所有的数据都存放在髙速缓存中的情况。  
现代处理器有专门的功能单元来执行加载和存储操作，这些单元有
内部的缓冲区来保存未完成的内存操作请求集合。
#### 5.12. 1 加载的性能
一个包含加载操作的程序的性能既依赖于流水线的能力，也依赖于加载单元的延迟。
要确定一台机器上加载操作的延迟，我们可
以建立由一系列加载操作组成的一个计算，一条
加载操作的结果决定下一条操作的地址。作为一
个例子，考虑函数图 5-3.1 中的函数 list_len，
它计算一个链表的长度。在这个函数的循环中，
变量 ls 的每个后续值依赖于指针引用 ls->next
读出的值。测试表明函数 list_len 的 CPE 为
4.00, 我们认为这直接表明了加载操作的延迟。
要弄懂这一点，考虑循环的汇编代码：
```
Tnner loop of list_len     ls in %rdi, len in %rax
.L3:                        loop:
  addq     $1, %rax           Increment   len
  movq     (%rdi),%rdi        ls = ls->next
  testq    %rdi,%rdi          Test ls
  jne      .L3                If nunnull , goto loop
```
![image]()  
第 3 行上的 movq 指令是这个循环中关键的瓶颈。后面寄存器％rdi 的每个值都依赖于
加载操作的结果，而加载操作又以％rdi 中的值作为它的地址。因此，直到前一次迭代的
加载操作完成，下一次迭代的加载操作才能开始。
#### 5.12.2 存储的性能
在迄今为止所有的示例中，我们只分析了大部分内存引用都是加载操作的函数，也就
是从内存位置读到寄存器中。与之对应的是存储（store)操作，它将一个寄存器值写到内
存。与加载操作一样，在大多数情况中，存储操作能够在完全流水线化的模式中工作，每
个周期开始一条新的存储。与到目前为止我们已经考虑过的其他操作不同，存储操作并不影响任何寄存器值。因
此，就其本性来说，一系列存储操作不会产生数据相关。只有加载操作会受存储操作结果
的影响，因为只有加载操作能从由存储操作写的那个位置读回值。
为了了解处理器如何区别这两种情况，以及为什么一种情况比另一种运行得慢，我们必
须更加仔细地看看加载和存储执行单元，如图 5-34 所示。存储单元包含一个存储缓冲区,
它包含已经被发射到存储单元而又还没有完成的存储操作的地址和数据，这里的完成包括
更新数据高速缓存。提供这样一个缓冲区，使得一系列存储操作不必等待每个操作都更新
高速缓存就能够执行。当一个加载操作发生时，它必须检查存储缓冲区中的条目，看有没
有地址相匹配。如果有地址相匹配（意味着在写的
字节与在读的字节有相同的地址）， 它就取出相应
的数据条目作为加载操作的结果。  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20215331.png)  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20215348.png)  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20215359.png)  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20215414.png)  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20215424.png)  
![image](https://github.com/sunhaofeng2001/-/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-09-12%20215446.png)  
这两个例子说明，内存操作的实现包括许多细微之处。对于寄存器操作，在指令被译
码成操作的时候，处理器就可以确定哪些指令会影响其他哪些指令。另一方面，对于内存
操作，只有到计算出加载和存储的地址被计算出来以后，处理器才能确定哪些指令会影响
其他的哪些。高效地处理内存操作对许多程序的性能来说至关重要。内存子系统使用了很
多优化，例如当操作可以独立地进行时，就利用这种潜在的并行性。
#### 5.13 应用：性能提高技术
虽然只考虑了有限的一组应用程序，但是我们能得出关于如何编写高效代码的很重要
的经验教训。我们已经描述了许多优化程序性能的基本策略：  
1) 高级设计。为遇到的问题选择适当的算法和数据结构。要特别警觉，避免使用那
些会渐进地产生糟糕性能的算法或编码技术。  
2) 基本编码原则。避免限制优化的因素，这样编译器就能产生高效的代码。  
•消除连续的函数调用。在可能时，将计算移到循环外。考虑有选择地妥协程序的模
块性以获得更大的效率。  
•消除不必要的内存引用。引人临时变量来保存中间结果。只有在最后的值计算出来
时，才将结果存放到数组或全局变量中。  
3) 低级优化。结构化代码以利用硬件功能。  
•展开循环，降低开销，并且使得进一步的优化成为可能。  
•通过使用例如多个累积变量和重新结合等技术，找到方法提高指令级并行。  
•用功能性的风格重写条件操作，使得编译采用条件数据传送。  
#### 5.14 确认和消除性能瓶颈
本节会描述如何使用代码剖析程序（code profiler), 这是在程序执行时收集性能数据的分析工具。
#### 5.14.1 程序剖析
程序剖析(profiling)运行程序的一个版本，其中插人了工具代码，以确定程序的各个
部分需要多少时间。这对于确认程序中我们需要集中注意力优化的部分是很有用的。剖析
的一个有力之处在于可以在现实的基准数据（benchmark data}上运行实际程序的同时，进
行剖析。  
Unix 系统提供了一个剖析程序 GPROF。这个程序产生两种形式的信息。首先，它确
定程序中每个函数花费了多少 CPU 时间。其次，它计算每个函数被调用的次数，以执行
调用的函数来分类。这两种形式的信息都非常有用。这些计时给出了不同函数在确定整体
运行时间中的相对重要性。调用信息使得我们能理解程序的动态行为。  
#### 5.15 小结
虽然关于代码优化的大多数论述都描述了编译器是如何能生成髙效代码的，但是应用程序员有很多方
法来协助编译器完成这项任务。没有任何编译器能用一个好的算法或数据结构代替低效率的算法或数据结
构，因此程序设计的这些方面仍然应该是程序员主要关心的。我们还看到妨碍优化的因素，例如内存别名
使用和过程调用，严重限制了编译器执行大量优化的能力。同样，程序员必须对消除这些妨碍优化的因素
负主要的责任。这些应该被看作好的编程习惯的一部分，因为它们可以用来消除不必要的工作。  
基本级别之外调整性能需要一些对处理器微体系结构的理解，描述处理器用来实现它的指令集体系
结构的底层机制。对于乱序处理器的情况，只需要知道一些关于操作、容量、延迟和功能单元发射时间
的信息，就能够基本地预测程序的性能了。  
我们研究了一系列技术，包括循环展开、创建多个累积变量和重新结合，它们可以利用现代处理器
提供的指令级并行。随着对优化的深人，研究产生的汇编代码以及试着理解机器如何执行计算变得重要
起来。确认由程序中的数据相关决定的关键路径，尤其是循环的不同迭代之间的数据相关，会收获良多。
我们还可以根据必须要计算的操作数量以及执行这些操作的功能单元的数量和发射时间，计算一个计算
的吞吐量界限。  
包含条件分支或与内存系统复杂交互的程序，比我们最开始考虑的简单循环程序，更难以分析和优
化。基本策略是使分支更容易预测，或者使它们很容易用条件数据传送来实现。我 们还必须注意存储和
加载操作。将数值保存在局部变量中，使得它们可以存放在寄存器中，这会很有帮助。  
当处理大型程序时. 将注意力集中在最耗时的部分变得很重要。代码剖析程序和相关的工具能帮助
我们系统地评价和改进程序性能。我们描述了 GPROF，一个标准的 Unix 剖析工具。还有更加复杂完善
的剖析程序可用，例如 Intel 的 VTUNE 程序开发系统，还有 Linux 系统基本上都有的 VALGRIND。这
些工具可以在过程级分解执行时间. 估计程序每个基本块（basic block)的性能。（基本块是内部没有控制
转移的指令序列，因此基本块总是整个被执行的。）


